{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys\n",
    "#sys.path.append('..')\n",
    "import deeplabcut\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import glob, os\n",
    "\n",
    "\n",
    "# Base path is the path containing the videos divided under subject directories. The path to any video looks like:\n",
    "# base_path / sub_ID / vid_name.ext (ext can be either avi or mp4 depending on the video)\n",
    "base_path = '/media/ssd_storage/work_repos/MGH/bootstrap_round3_2019_08_14_videos/'\n",
    "\n",
    "# Working directory is the path to a folder where all DeepLabCut project files will be stored for the\n",
    "# current run of experiments.\n",
    "work_dir = '/media/ssd_storage/work_repos/MGH/deeplabcut_mgh_pose/experiments/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List videos from all subject directories and store them separately as we want different model per subject\n",
    "videos_bw46 = glob.glob(os.path.join(base_path, 'BW46', '*.avi'))\n",
    "videos_mg51b = glob.glob(os.path.join(base_path, 'MG51b', '*.avi'))\n",
    "videos_mg117 = glob.glob(os.path.join(base_path, 'MG117', '*.avi'))\n",
    "videos_mg118 = glob.glob(os.path.join(base_path, 'MG118', '*.avi'))\n",
    "videos_mg120b = glob.glob(os.path.join(base_path, 'MG120b', '*.avi'))\n",
    "\n",
    "# Create new project for each different subject with arguments: project name, experimenter name, video path list,\n",
    "# working directory path and a flag indicating whether the videos should be copied to project folder from source\n",
    "# directory or not.\n",
    "# The return values from these create_new_project function calls will be the path to their respective\n",
    "# config.yaml files. For example, for BW46 here, the path should be:\n",
    "# work_dir / 'mgh_pose_dlc_BW46_2-Kalpit-YYYY-MM-DD' / config.yaml\n",
    "config_path_bw46 = deeplabcut.create_new_project(\n",
    "    project='mgh_pose_dlc_BW46_2',\n",
    "    experimenter='Kalpit',\n",
    "    videos=videos_bw46,\n",
    "    working_directory=work_dir,\n",
    "    copy_videos=True\n",
    ")\n",
    "config_path_mg51b = deeplabcut.create_new_project(\n",
    "    project='mgh_pose_dlc_MG51b_2',\n",
    "    experimenter='Kalpit',\n",
    "    videos=videos_mg51b,\n",
    "    working_directory=work_dir,\n",
    "    copy_videos=True\n",
    ")\n",
    "config_path_mg117 = deeplabcut.create_new_project(\n",
    "    project='mgh_pose_dlc_MG117_2',\n",
    "    experimenter='Kalpit',\n",
    "    videos=videos_mg117,\n",
    "    working_directory=work_dir,\n",
    "    copy_videos=True\n",
    ")\n",
    "config_path_mg118 = deeplabcut.create_new_project(\n",
    "    project='mgh_pose_dlc_MG118_2',\n",
    "    experimenter='Kalpit',\n",
    "    videos=videos_mg118,\n",
    "    working_directory=work_dir,\n",
    "    copy_videos=True\n",
    ")\n",
    "config_path_mg120b = deeplabcut.create_new_project(\n",
    "    project='mgh_pose_dlc_MG120b_2',\n",
    "    experimenter='Kalpit',\n",
    "    videos=videos_mg120b,\n",
    "    working_directory=work_dir,\n",
    "    copy_videos=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract frames from the videos mentioned in the YAML at config_path and check if they are labeled\n",
    "# (I generated labels by hand as we had already annotated them. This process is difficult to explain\n",
    "# and I won't cover it here). For any new project for pose estimation, the annotation tool provided in DLC\n",
    "# should be used as it makes things streamlined and much easier.\n",
    "config_path_bw46 = os.path.join(work_dir, 'mgh_pose_dlc_BW46_2-Kalpit-2019-08-14', 'config.yaml')\n",
    "config_path_mg51b = os.path.join(work_dir, 'mgh_pose_dlc_MG51b_2-Kalpit-2019-08-14', 'config.yaml')\n",
    "config_path_mg117 = os.path.join(work_dir, 'mgh_pose_dlc_MG117_2-Kalpit-2019-08-14', 'config.yaml')\n",
    "config_path_mg118 = os.path.join(work_dir, 'mgh_pose_dlc_MG118_2-Kalpit-2019-08-14', 'config.yaml')\n",
    "config_path_mg120b = os.path.join(work_dir, 'mgh_pose_dlc_MG120b_2-Kalpit-2019-08-14', 'config.yaml')\n",
    "\n",
    "# Set the config_path to a value according to which subject you'd want to process\n",
    "config_path = config_path_mg120b\n",
    "# extract_frames function extracts frames from the videos using uniform or k-means sampling (to make sure\n",
    "# there is enough variability in pose frames to be annotated). These extracted frames should then be annotated\n",
    "# using their annotation GUI. I had not done that (I imported annotations we had already done), but it should be\n",
    "# easy to follow from their documentation on Github.\n",
    "# deeplabcut.extract_frames(config_path, 'automatic', 'uniform', crop=False)\n",
    "\n",
    "# Once the labeling is done, call this function to check the labels by plotting them on the frames and saving\n",
    "# these frames with annotations plotted. Check these frames to validate the annotation accuracy.\n",
    "# deeplabcut.check_labels(config_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this function to create the training dataset for different subjects. This function divides the annotations\n",
    "# and the frames into training and validation sets that are used to train / validate the pose estimation model.\n",
    "deeplabcut.create_training_dataset(config_path_bw46)\n",
    "deeplabcut.create_training_dataset(config_path_mg51b)\n",
    "deeplabcut.create_training_dataset(config_path_mg117)\n",
    "deeplabcut.create_training_dataset(config_path_mg118)\n",
    "deeplabcut.create_training_dataset(config_path_mg120b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the network for different subjects one by one (the parameters to the train_network are good I think.\n",
    "# You can add something by referring the deeplabcut readme if you want to)\n",
    "config_path = config_path_bw46   # Change this value for different subject training\n",
    "deeplabcut.train_network(config_path,\n",
    "                         shuffle=1,\n",
    "                         trainingsetindex=0,\n",
    "                         max_snapshots_to_keep=5,\n",
    "                         autotune=False,\n",
    "                         displayiters=100,\n",
    "                         saveiters=20000,\n",
    "                         maxiters=800000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = config_path_bw46  # Change this to evaluate for different subjects\n",
    "# Analyze videos (generate predictions) and plot the predictions on the videos (this takes a long time)\n",
    "# This is the path to the folder where you have the test videos - the videos that were not used in either testing\n",
    "# or validation.\n",
    "base_vpath = '/media/data_cifs/MGH/videos/'\n",
    "# Check for both avi and mp4 videos (unless they're repeated in the folder). Change according to requirement.\n",
    "videos = glob.glob(os.path.join(vpath, 'BW46', '*.avi'))\n",
    "videos += glob.glob(os.path.join(base_vpath, 'BW46', '*.mp4'))\n",
    "deeplabcut.analyze_videos(config_path, videos, save_as_csv=True)\n",
    "\n",
    "# This function creates the labeled video by plotting the predicted pose onto the frames so that the video can be\n",
    "# visualized for judging the model's performance.\n",
    "#deeplabcut.create_labeled_video(config_path, videos, save_frames=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
